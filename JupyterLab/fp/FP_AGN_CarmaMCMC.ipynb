{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb4f8f1-0bc3-4c71-b437-708f4335df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a68717e-86f6-4a88-ba6d-3ee62f14f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317.2915437\n",
      "[2458259.9212153 2458263.9602315 2458267.9387037 2458270.9585648\n",
      " 2458275.9598727 2458278.9177546 2458284.8969097 2458287.9179051\n",
      " 2458290.9182986 2458293.9178819 2458297.9400579 2458302.9202315\n",
      " 2458305.9410764 2458312.8554398 2458315.8971875 2458318.8972917\n",
      " 2458321.8978009 2458324.9178009 2458329.8990046 2458332.957338\n",
      " 2458338.859294  2458338.8602083 2458348.8544444 2458360.8576042\n",
      " 2458363.7961111 2458366.77125   2458369.7752083 2458372.7527199\n",
      " 2458375.7820833 2458378.7957986 2458384.7506481 2458387.7098032\n",
      " 2458387.7107176 2458388.7951157 2458389.6899653 2458424.649294\n",
      " 2458425.6650347 2458426.6680093 2458426.6689699 2458427.6662037\n",
      " 2458428.6483218 2458429.6678125 2458429.6687384 2458430.644838\n",
      " 2458431.6025579 2458432.6475926 2458435.6274306 2458457.5916088\n",
      " 2458457.5925231 2458608.9587731 2458632.9535417 2458634.9478588\n",
      " 2458635.9822917 2458638.9439583 2458641.938831  2458644.9395602\n",
      " 2458647.876088  2458665.9816667 2458668.9427315 2458674.9234259\n",
      " 2458677.8154861 2458677.8298032 2458680.9426273 2458684.884537\n",
      " 2458684.8854977 2458690.7980671 2458690.7989699 2458692.8566782\n",
      " 2458693.8140509 2458693.8149537 2458695.8863657 2458698.8326389\n",
      " 2458704.8704977 2458708.9228009 2458712.7062963 2458712.7071991\n",
      " 2458714.7433333 2458725.8160417 2458732.799213  2458743.706169\n",
      " 2458747.8007407 2458750.7064699 2458757.6440162 2458766.6916088\n",
      " 2458769.6930208 2458773.6856481 2458777.6212037 2458790.5981019\n",
      " 2458794.6280093 2458797.6284838 2458804.6735648 2458996.921331\n",
      " 2458999.9145023 2459023.8416898 2459026.8769329 2459030.8352778\n",
      " 2459033.9410532 2459039.8506481 2459042.8558565 2459045.9401505\n",
      " 2459050.8766782 2459053.8560648 2459056.8984491 2459067.828125\n",
      " 2459072.8350231 2459076.7940856 2459079.8155556 2459082.7927199\n",
      " 2459095.7752315 2459098.7262153 2459108.7727431 2459114.7097917\n",
      " 2459123.6695255 2459125.689213  2459130.6879282 2459135.732419\n",
      " 2459137.7283449 2459143.6864699 2459145.7179745 2459149.6708449\n",
      " 2459150.6480671 2459151.6492245 2459152.7388194 2459156.6051042\n",
      " 2459158.6792361 2459165.6618519 2459167.6640162 2459168.6630787\n",
      " 2459170.6748611 2459172.5957986 2459178.6090394 2459180.6660417\n",
      " 2459182.6295486 2459184.6282292 2459186.6284954 2459334.9807176\n",
      " 2459342.9684722 2459345.9275347 2459348.9444907 2459352.962662\n",
      " 2459354.9446644 2459357.9218403 2459363.9542824 2459367.9389931\n",
      " 2459369.9010532 2459371.899838  2459374.9003819 2459380.9059375\n",
      " 2459382.9181944 2459385.9182755 2459387.8579514 2459391.9189931\n",
      " 2459401.8851736 2459403.8912847 2459409.8993403 2459411.8333333\n",
      " 2459414.8998264 2459416.857662  2459418.8374769 2459422.7806829\n",
      " 2459424.7767708 2459426.8511227 2459428.8206944 2459430.8127546\n",
      " 2459435.8793634 2459438.8746065 2459440.7911921 2459442.7934606\n",
      " 2459444.8163773 2459449.7316898 2459451.7313426 2459453.7103009\n",
      " 2459455.7316898 2459459.774294  2459461.7110069 2459463.7120718\n",
      " 2459465.7127546 2459467.7114236 2459469.7335648 2459471.755625\n",
      " 2459476.7346759 2459478.7939583 2459480.7977083 2459488.7400694\n",
      " 2459494.6697917 2459504.6895023 2459510.7240972 2459521.6918866\n",
      " 2459522.6286343 2459523.6488773 2459524.6277894 2459525.7054398\n",
      " 2459527.6459259 2459537.6083796 2459540.6031713 2459542.6012847\n",
      " 2459711.9341088 2459722.9210417 2459722.9579745 2459725.958831\n",
      " 2459727.9427083 2459731.8975694 2459733.9584259 2459738.9172338\n",
      " 2459740.9190972 2459742.9394907 2459744.9390278 2459749.9198148\n",
      " 2459753.9232407]\n"
     ]
    }
   ],
   "source": [
    "filename = 'BAT_AGN_ZTF_ForcedPhotometry_LightCurves_AllBands.parquet'\n",
    "fp_dataframe = pd.read_parquet(filename)\n",
    "\n",
    "field = '389'\n",
    "filter_type = 'g'\n",
    "\n",
    "df_field = fp_dataframe.loc[fp_dataframe['field'] == field]\n",
    "df_filter = df_field.loc[df_field['filter'] == filter_type]\n",
    "\n",
    "print(df_filter['RA'].to_numpy()[0])\n",
    "print(df_filter['JD'].to_numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a4a715-2730-43f0-a6b5-439e89848667",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parallel Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2945b-8008-47aa-8026-415e19814619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import pandas\n",
    "import glob\n",
    "import emcee\n",
    "\n",
    "import eztao\n",
    "import eztao.ts\n",
    "\n",
    "import celerite\n",
    "\n",
    "import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac2ef9e-f500-43c1-94a3-4c31d9b94915",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Define CARMA function for DRW\n",
    "################################\n",
    "\n",
    "def get_carma_parameter(tau, amp):\n",
    "    \"\"\"Get DRW parameters in CARMA notation (alpha_*/beta_*).\n",
    "\n",
    "    alpha_1 = -1 / tau\n",
    "    sigma^2 = tau * sigma_kbs^2 / 2\n",
    "    sigma_kbs = np.sqrt( 2 * sigma^2 / tau )\n",
    "    beta_0 = sigma_kbs\n",
    "\n",
    "    Returns:\n",
    "        [alpha_1, beta_0].\n",
    "    \"\"\"\n",
    "    return [-1.0 / tau, numpy.sqrt( 2.0 * amp**2.0 / tau)]\n",
    "\n",
    "################################\n",
    "# Define the prior and log-probability functions for MCMC\n",
    "################################\n",
    "\n",
    "# prior function for tau_perturb\n",
    "def lnprior_perturb(theta):\n",
    "    \"\"\"Prior on perturbation timescale. Note: this is a wedge like prior.\"\"\"\n",
    "\n",
    "    # determine DHO timescales\n",
    "    log10_tau_perturb = (theta[-1] - theta[-2])/numpy.log(10)\n",
    "    if -3 <= log10_tau_perturb <= 5:\n",
    "        prior = 0\n",
    "    else:\n",
    "        prior = -(numpy.abs(log10_tau_perturb - 1) - 4)\n",
    "\n",
    "    return prior\n",
    "\n",
    "def lnprior_bounds(theta):\n",
    "    \"\"\"Prior on AR and MA parameters. This is a flat prior.\"\"\"\n",
    "\n",
    "    # Place some bounds on the parameter space\n",
    "    bounds_low = numpy.array([-15, -15, -20, -20])\n",
    "    bounds_high = numpy.array([15, 15, 10, 10])\n",
    "\n",
    "    log_a1, log_a2, log_b0, log_b1 = theta\n",
    "    if ( \n",
    "        bounds_low[0] < log_a1 < bounds_high[0] \n",
    "        and bounds_low[1] < log_a2 < bounds_high[1] \n",
    "        and bounds_low[2] < log_b0 < bounds_high[2] \n",
    "        and bounds_low[3] < log_b1 < bounds_high[3] \n",
    "       ):\n",
    "        return 0.0\n",
    "    return -numpy.inf\n",
    "\n",
    "# We'll use the eztao version which effectively returns \"gp.log_likelihood\" from the GP and np.inf otherwise\n",
    "def lnlike(theta, y, gp):\n",
    "    return -eztao.ts.neg_param_ll(theta, y, gp)\n",
    "\n",
    "def lnprob(theta, y, gp):\n",
    "    lp_bounds = lnprior_bounds(theta)\n",
    "    lp_perturb = lnprior_perturb(theta)                              \n",
    "    if not numpy.isfinite(lp_bounds):\n",
    "        return -numpy.inf\n",
    "    return lp_bounds + lp_perturb + lnlike(theta, y, gp)\n",
    "\n",
    "################################\n",
    "# Define other functions\n",
    "################################\n",
    "\n",
    "# chi-sqared\n",
    "def chisqg(y_data, y_model, sd=None):\n",
    "    chisq = numpy.nansum(((y_data-y_model)/sd)**2)\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfbf22e-3a02-4800-850b-987bf6203070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getCARMAstats(filter_type, field):\n",
    "    ################################\n",
    "    # setup\n",
    "    ################################\n",
    "    \n",
    "    # read-in light curve\n",
    "    file = 'BAT_AGN_ZTF_ForcedPhotometry_LightCurves_AllBands.parquet'\n",
    "    df = pandas.read_parquet(file)\n",
    "    \n",
    "    # grab row in df that contains field and filter_type\n",
    "    df = df.loc[df['field'] == str(field)]\n",
    "    df = df.loc[df['filter'] == filter_type]\n",
    "    \n",
    "    # obtain values from df\n",
    "    ra = df_filter['ra'].values[0]\n",
    "    dec = df_filter['dec'].values[0]\n",
    "    t = df['mjd'].values\n",
    "    y_real = df['mag'].values\n",
    "    yerr_real = df['magerr'].values\n",
    "    lc_length = len(t)\n",
    "    \n",
    "    # generate filename of FP LC\n",
    "    file_name = f'fp_lc_{ra}_{dec}_field_{field}.csv'\n",
    "    \n",
    "    # invert the magnitudes\n",
    "    y_real_inverted = (min(y_real)-y_real)\n",
    "\n",
    "    # normalize to unit standard deviation and zero mean\n",
    "    y = (y_real_inverted - numpy.mean(y_real_inverted))/numpy.std(y_real_inverted)\n",
    "    yerr = yerr_real/numpy.std(y_real_inverted)\n",
    "        \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # DRW Process\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    # obtain best-fit\n",
    "    bounds = [(0.01, 10.0), (0.01, 10.0)]\n",
    "    best_drw = eztao.ts.drw_fit(t, y, yerr, user_bounds=bounds)\n",
    "    \n",
    "    # get best-fit in CARMA space\n",
    "    best_drw_arma = numpy.exp(get_carma_parameter(best_drw[0], best_drw[1]))\n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # DHO Process\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    # obtain best-fit\n",
    "    bounds = [(-15, 15), (-15, 15), (-20, 10), (-20, 10)]\n",
    "    best_dho = eztao.ts.dho_fit(t, y, yerr, user_bounds=bounds)\n",
    "\n",
    "    # Create the GP model -- instead of creating a \"model\" function that is then called by the \"lnlike\" function from tutorial,\n",
    "    #  we will create a GP that will be passed as an argument to the MCMC sampler. This will be the \"gp\" that is passed to\n",
    "    #  the \"lnprob\" and \"param_ll\" functions\n",
    "    dho_kernel = eztao.carma.DHO_term(*numpy.log(best_dho))\n",
    "    dho_gp = celerite.GP(dho_kernel, mean=numpy.median(y))\n",
    "    dho_gp.compute(t, yerr)\n",
    "\n",
    "    ################################\n",
    "    # MCMC\n",
    "    ################################\n",
    "\n",
    "    # Initalize MCMC\n",
    "    data = (t, y, yerr)\n",
    "    nwalkers = 128\n",
    "    niter = 2048\n",
    "\n",
    "    initial = numpy.array(numpy.log(best_dho))\n",
    "    ndim = len(initial)\n",
    "    p0 = [numpy.array(initial) + 1e-7 * numpy.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "    # Create the MCMC sampler -- note that the GP is passed as an argument in addition to the data\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=[y, dho_gp])\n",
    "\n",
    "    # run a burn-in surrounding the best-fit parameters obtained above\n",
    "    p0, lp, _ = sampler.run_mcmc(p0, 200)\n",
    "    sampler.reset()\n",
    "\n",
    "    # clear up the stored chain from burn-in, rerun the MCMC\n",
    "    pos, prob, state = sampler.run_mcmc(p0, niter);\n",
    "\n",
    "    ################################\n",
    "    # Obtain the Best Fit: theta_max\n",
    "    ################################\n",
    "\n",
    "    # put all the samples that explored in MCMC into a single array\n",
    "    samples = sampler.flatchain\n",
    "    \n",
    "    # find the parameters that have the best fit \n",
    "    theta_max_index = numpy.argmax(sampler.flatlnprobability)\n",
    "    theta_max_probability = sampler.flatlnprobability[theta_max_index]\n",
    "   \n",
    "    theta_max  = samples[theta_max_index] # these are in log-space\n",
    "    theta_max_norm = numpy.exp(theta_max) # take the exponent to get into 'normal' space\n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # Simulate and Return\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    ################################\n",
    "    # Simulate and plot light curves\n",
    "    ################################\n",
    "    \n",
    "    # create simulated light curve\n",
    "    drw_sim_t, drw_sim_y, drw_sim_yerr = eztao.ts.carma_sim.pred_lc(t, y, yerr, best_drw_arma, 1, t)\n",
    "    dho_sim_t, dho_sim_y, dho_sim_yerr = eztao.ts.carma_sim.pred_lc(t, y, yerr, theta_max_norm, 2, t)\n",
    "    \n",
    "    # directory to save plots to\n",
    "    plot_dir = 'plots_and_figures/carma_plots'\n",
    "    # plot drw\n",
    "    plot = True  \n",
    "    if plot:\n",
    "        matplotlib.pyplot.figure()\n",
    "        matplotlib.pyplot.errorbar(t, y, yerr=yerr, label='data',\n",
    "                                   linestyle=\"None\", marker='.', ms=3., color='purple', ecolor='0.8')\n",
    "        matplotlib.pyplot.plot(drw_sim_t, drw_sim_y, label=f'drw {best_drw_arma}')\n",
    "        matplotlib.pyplot.legend()\n",
    "        matplotlib.pyplot.savefig(f'{plot_dir}/{file_name}_drw_fit.png')\n",
    "        matplotlib.pyplot.close()\n",
    "\n",
    "        # plot dho\n",
    "        matplotlib.pyplot.figure()\n",
    "        matplotlib.pyplot.errorbar(t, y, yerr=yerr, label='data',\n",
    "                                   linestyle=\"None\", marker='.', ms=3., color='purple', ecolor='0.8')\n",
    "        matplotlib.pyplot.plot(dho_sim_t, dho_sim_y, label=f'dho {theta_max_norm}')\n",
    "        matplotlib.pyplot.legend()\n",
    "        matplotlib.pyplot.savefig(f'{plot_dir}/{file_name}_dho_fit.png')\n",
    "        matplotlib.pyplot.close()\n",
    "    \n",
    "    ################################\n",
    "    # Determine best fit\n",
    "    ################################\n",
    "    \n",
    "    # get chi-squared from sim light curves\n",
    "    chisq_drw = chisqg(y, drw_sim_y, yerr)\n",
    "    chisq_dho = chisqg(y, dho_sim_y, yerr)\n",
    "    \n",
    "    # determine best fit\n",
    "    best_fit = 'DRW'\n",
    "    if chisq_drw > chisq_dho and not numpy.isinf(chisq_dho):\n",
    "        best_fit = 'DHO'\n",
    "    \n",
    "    ################################\n",
    "    # Return\n",
    "    ################################\n",
    "    \n",
    "    return file_name, ra, dec, t, y_real, yerr_real, best_drw, best_drw_arma, chisq_drw, best_dho, theta_max_norm, theta_max_probability, chisq_dho, best_fit, lc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38774013-c967-4521-bcf4-280b1f72c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppservers = ()\n",
    "\n",
    "# creates jobserver with ncpus workers\n",
    "ncpus = 24\n",
    "job_server = pp.Server(ncpus, ppservers=ppservers)\n",
    "\n",
    "print(\"Starting pp with\", job_server.get_ncpus(), \"workers\")\n",
    "\n",
    "# get list of data files\n",
    "#repository = glob.glob('data/*.csv')\n",
    "repository = glob.glob('../../AGN_LightCurves/*.parquet')\n",
    "\n",
    "# intialize lists to save to\n",
    "file_names = []\n",
    "times = []\n",
    "magnitudes = []\n",
    "mag_errors = []\n",
    "ras = []\n",
    "decs =[]\n",
    "best_fit_drws = []\n",
    "best_fit_drws_arma = []\n",
    "best_fit_dhos = []\n",
    "best_mcmc_dhos = []\n",
    "dho_probabilities = []\n",
    "chi_squared_drw = []\n",
    "chi_squared_dho = []\n",
    "best_fits = []\n",
    "lc_lengths = []\n",
    "\n",
    "# Submit a list of jobs running getCARMAstats for each file in repository\n",
    "# getCARMAstats - the function\n",
    "# (file,) - file with AGN lc\n",
    "# (chisqg, ...) - tuple with functions on which getCARMAstats depends\n",
    "# (\"numpy\", ...) - tuple with package dependencies to be imported\n",
    "jobs = [(file, job_server.submit(getCARMAstats ,(file,), \n",
    "                                 (get_carma_parameter, lnprior_perturb, lnprior_bounds, lnlike, lnprob, chisqg,), \n",
    "                                 (\"numpy\", \"matplotlib.pyplot\", \"pandas\", \"emcee\", \"eztao\", \"eztao.ts\",\n",
    "                                  \"celerite\"))) for file in repository]\n",
    "\n",
    "job_num = 1\n",
    "for file, job in jobs:\n",
    "    # start job\n",
    "    file_name, ra, dec, t, y, yerr, best_drw, best_drw_arma, chisq_drw, best_dho, best_mcmc_dho, dho_probability, chisq_dho, best_fit, lc_length = job()\n",
    "        \n",
    "    # save data from job\n",
    "    file_names.append(file_name)\n",
    "    ras.append(ra)\n",
    "    decs.append(dec)\n",
    "    times.append(t)\n",
    "    magnitudes.append(y)\n",
    "    mag_errors.append(yerr)\n",
    "    best_fit_drws.append(best_drw)\n",
    "    best_fit_drws_arma.append(best_drw_arma)\n",
    "    chi_squared_drw.append(chisq_drw)\n",
    "    best_fit_dhos.append(best_dho)\n",
    "    best_mcmc_dhos.append(best_mcmc_dho)\n",
    "    dho_probabilities.append(dho_probability)\n",
    "    chi_squared_dho.append(chisq_dho)\n",
    "    best_fits.append(best_fit)\n",
    "    lc_lengths.append(lc_length)\n",
    "    \n",
    "    #print(f'Completed [{job_num}/{len(jobs)}]: {file_name}')\n",
    "    job_num += 1\n",
    "\n",
    "job_server.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62bbc4a-8291-4c4e-b5b8-dbc8df7470ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "agn_fit_data = pandas.DataFrame({'Filenames': file_names, 'RA': ras, 'DEC': decs, 'Times (MJD)': times, \n",
    "                                 'Magnitudes': magnitudes, 'Mag Errors': mag_errors, \n",
    "                                 'Best DRW Fit': best_fit_drws, 'Best DRW ARMA Fit': best_fit_drws_arma, 'DRW chisq': chi_squared_drw,\n",
    "                                 'Best DHO Fit': best_fit_dhos, 'DHO MCMC Fit': best_mcmc_dhos, 'DHO MCMC Probability': dho_probabilities, 'DHO chisq': chi_squared_dho,\n",
    "                                 'Best Fit': best_fits, 'LC Length': lc_lengths})\n",
    "\n",
    "# save dataframe\n",
    "agn_fit_data.to_csv('agn_fit_data.csv')\n",
    "agn_fit_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
