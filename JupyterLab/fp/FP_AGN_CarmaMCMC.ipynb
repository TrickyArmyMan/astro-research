{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb4f8f1-0bc3-4c71-b437-708f4335df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a68717e-86f6-4a88-ba6d-3ee62f14f229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>JD</th>\n",
       "      <th>mag</th>\n",
       "      <th>magerr</th>\n",
       "      <th>filter</th>\n",
       "      <th>field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>317.2915437</td>\n",
       "      <td>-9.6707397</td>\n",
       "      <td>[2458259.9212153, 2458263.9602315, 2458267.938...</td>\n",
       "      <td>[18.2467226735013, nan, nan, nan, nan, nan, 16...</td>\n",
       "      <td>[0.0477328813841479, -0.0566556623768301, -0.5...</td>\n",
       "      <td>g</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RA         DEC  \\\n",
       "1045  317.2915437  -9.6707397   \n",
       "\n",
       "                                                     JD  \\\n",
       "1045  [2458259.9212153, 2458263.9602315, 2458267.938...   \n",
       "\n",
       "                                                    mag  \\\n",
       "1045  [18.2467226735013, nan, nan, nan, nan, nan, 16...   \n",
       "\n",
       "                                                 magerr filter field  \n",
       "1045  [0.0477328813841479, -0.0566556623768301, -0.5...      g   389  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'BAT_AGN_ZTF_ForcedPhotometry_LightCurves_AllBands.parquet'\n",
    "fp_dataframe = pd.read_parquet(filename)\n",
    "\n",
    "field = '389'\n",
    "filter_type = 'g'\n",
    "\n",
    "df = fp_dataframe.loc[fp_dataframe['filter'] == filter_type]\n",
    "df = df.loc[df['field'] == field]\n",
    "df\n",
    "#print(df['RA'].to_numpy()[0])\n",
    "#print(df['JD'].to_numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db39a62f-e692-4e89-835c-4201c4346dd6",
   "metadata": {},
   "source": [
    "### How to Identify/Remove nan indices in FP LCs\n",
    "Masking with np.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2a345-f364-49b3-9550-373e4e4433b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_ind = np.where((row['mag'] > 10) & (row['mag'] < 30))[0]\n",
    "\n",
    "t = row['JD'][good_ind]\n",
    "y = row['mag'][good_ind]\n",
    "e = row['magerr'][good_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a4a715-2730-43f0-a6b5-439e89848667",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parallel Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff2945b-8008-47aa-8026-415e19814619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import pandas\n",
    "import glob\n",
    "import emcee\n",
    "\n",
    "import eztao\n",
    "import eztao.ts\n",
    "\n",
    "import celerite\n",
    "\n",
    "import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac2ef9e-f500-43c1-94a3-4c31d9b94915",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Define CARMA function for DRW\n",
    "################################\n",
    "\n",
    "def get_carma_parameter(tau, amp):\n",
    "    \"\"\"Get DRW parameters in CARMA notation (alpha_*/beta_*).\n",
    "\n",
    "    alpha_1 = -1 / tau\n",
    "    sigma^2 = tau * sigma_kbs^2 / 2\n",
    "    sigma_kbs = np.sqrt( 2 * sigma^2 / tau )\n",
    "    beta_0 = sigma_kbs\n",
    "\n",
    "    Returns:\n",
    "        [alpha_1, beta_0].\n",
    "    \"\"\"\n",
    "    return [-1.0 / tau, numpy.sqrt( 2.0 * amp**2.0 / tau)]\n",
    "\n",
    "################################\n",
    "# Define the prior and log-probability functions for MCMC\n",
    "################################\n",
    "\n",
    "# prior function for tau_perturb\n",
    "def lnprior_perturb(theta):\n",
    "    \"\"\"Prior on perturbation timescale. Note: this is a wedge like prior.\"\"\"\n",
    "\n",
    "    # determine DHO timescales\n",
    "    log10_tau_perturb = (theta[-1] - theta[-2])/numpy.log(10)\n",
    "    if -3 <= log10_tau_perturb <= 5:\n",
    "        prior = 0\n",
    "    else:\n",
    "        prior = -(numpy.abs(log10_tau_perturb - 1) - 4)\n",
    "\n",
    "    return prior\n",
    "\n",
    "def lnprior_bounds(theta):\n",
    "    \"\"\"Prior on AR and MA parameters. This is a flat prior.\"\"\"\n",
    "\n",
    "    # Place some bounds on the parameter space\n",
    "    bounds_low = numpy.array([-15, -15, -20, -20])\n",
    "    bounds_high = numpy.array([15, 15, 10, 10])\n",
    "\n",
    "    log_a1, log_a2, log_b0, log_b1 = theta\n",
    "    if ( \n",
    "        bounds_low[0] < log_a1 < bounds_high[0] \n",
    "        and bounds_low[1] < log_a2 < bounds_high[1] \n",
    "        and bounds_low[2] < log_b0 < bounds_high[2] \n",
    "        and bounds_low[3] < log_b1 < bounds_high[3] \n",
    "       ):\n",
    "        return 0.0\n",
    "    return -numpy.inf\n",
    "\n",
    "# We'll use the eztao version which effectively returns \"gp.log_likelihood\" from the GP and np.inf otherwise\n",
    "def lnlike(theta, y, gp):\n",
    "    return -eztao.ts.neg_param_ll(theta, y, gp)\n",
    "\n",
    "def lnprob(theta, y, gp):\n",
    "    lp_bounds = lnprior_bounds(theta)\n",
    "    lp_perturb = lnprior_perturb(theta)                              \n",
    "    if not numpy.isfinite(lp_bounds):\n",
    "        return -numpy.inf\n",
    "    return lp_bounds + lp_perturb + lnlike(theta, y, gp)\n",
    "\n",
    "################################\n",
    "# Define other functions\n",
    "################################\n",
    "\n",
    "# chi-sqared\n",
    "def chisqg(y_data, y_model, sd=None):\n",
    "    chisq = numpy.nansum(((y_data-y_model)/sd)**2)\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dfbf22e-3a02-4800-850b-987bf6203070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass string list key where:\n",
    "# - key[0] = dataframe filename + location\n",
    "# - key[1] = filter (i.e r, g, b, i) \n",
    "# - key[2] = field\n",
    "def getCARMAstats(key):\n",
    "    ################################\n",
    "    # setup\n",
    "    ################################\n",
    "    \n",
    "    # read-in FP df\n",
    "    df = pandas.read_parquet(key[0])\n",
    "    \n",
    "    # grab row in df that has the same filter and field\n",
    "    df = df.loc[df['filter'] == key[1]]\n",
    "    df = df.loc[df['field'] == key[2]]\n",
    "    \n",
    "    # obtain values from df\n",
    "    ra = df['RA'].to_numpy()[0]\n",
    "    dec = df['DEC'].to_numpy()[0]\n",
    "    t = df['JD'].to_numpy()[0]\n",
    "    y_real = df['mag'].to_numpy()[0]\n",
    "    yerr_real = df['magerr'].to_numpy()[0]\n",
    "    \n",
    "    # exclude indicies with nan's or outliers\n",
    "    good_ind = numpy.where((y_real > 10) & (y_real < 30))[0]\n",
    "    t = t[good_ind]\n",
    "    y_real = y_real[good_ind]\n",
    "    yerr_real = yerr_real[good_ind]\n",
    "    \n",
    "    lc_length = len(t)\n",
    "    \n",
    "    # generate filename of FP LC\n",
    "    file_name = f'fp_lc_{ra}_{dec}_field_{key[2]}.csv'\n",
    "    \n",
    "    # invert the magnitudes\n",
    "    y_real_inverted = (min(y_real)-y_real)\n",
    "\n",
    "    # normalize to unit standard deviation and zero mean\n",
    "    y = (y_real_inverted - numpy.mean(y_real_inverted))/numpy.std(y_real_inverted)\n",
    "    yerr = yerr_real/numpy.std(y_real_inverted)\n",
    "        \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # DRW Process\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    # obtain best-fit\n",
    "    bounds = [(0.01, 10.0), (0.01, 10.0)]\n",
    "    best_drw = eztao.ts.drw_fit(t, y, yerr, user_bounds=bounds)\n",
    "    \n",
    "    # get best-fit in CARMA space\n",
    "    best_drw_arma = numpy.exp(get_carma_parameter(best_drw[0], best_drw[1]))\n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # DHO Process\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    # obtain best-fit\n",
    "    bounds = [(-15, 15), (-15, 15), (-20, 10), (-20, 10)]\n",
    "    best_dho = eztao.ts.dho_fit(t, y, yerr, user_bounds=bounds)\n",
    "\n",
    "    # Create the GP model -- instead of creating a \"model\" function that is then called by the \"lnlike\" function from tutorial,\n",
    "    #  we will create a GP that will be passed as an argument to the MCMC sampler. This will be the \"gp\" that is passed to\n",
    "    #  the \"lnprob\" and \"param_ll\" functions\n",
    "    dho_kernel = eztao.carma.DHO_term(*numpy.log(best_dho))\n",
    "    dho_gp = celerite.GP(dho_kernel, mean=numpy.median(y))\n",
    "    dho_gp.compute(t, yerr)\n",
    "\n",
    "    ################################\n",
    "    # MCMC\n",
    "    ################################\n",
    "\n",
    "    # Initalize MCMC\n",
    "    data = (t, y, yerr)\n",
    "    nwalkers = 128\n",
    "    niter = 2048\n",
    "\n",
    "    initial = numpy.array(numpy.log(best_dho))\n",
    "    ndim = len(initial)\n",
    "    p0 = [numpy.array(initial) + 1e-7 * numpy.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "    # Create the MCMC sampler -- note that the GP is passed as an argument in addition to the data\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=[y, dho_gp])\n",
    "\n",
    "    # run a burn-in surrounding the best-fit parameters obtained above\n",
    "    p0, lp, _ = sampler.run_mcmc(p0, 200)\n",
    "    sampler.reset()\n",
    "\n",
    "    # clear up the stored chain from burn-in, rerun the MCMC\n",
    "    pos, prob, state = sampler.run_mcmc(p0, niter);\n",
    "\n",
    "    ################################\n",
    "    # Obtain the Best Fit: theta_max\n",
    "    ################################\n",
    "\n",
    "    # put all the samples that explored in MCMC into a single array\n",
    "    samples = sampler.flatchain\n",
    "    \n",
    "    # find the parameters that have the best fit \n",
    "    theta_max_index = numpy.argmax(sampler.flatlnprobability)\n",
    "    theta_max_probability = sampler.flatlnprobability[theta_max_index]\n",
    "   \n",
    "    theta_max  = samples[theta_max_index] # these are in log-space\n",
    "    theta_max_norm = numpy.exp(theta_max) # take the exponent to get into 'normal' space\n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # Simulate and Return\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    ################################\n",
    "    # Simulate and plot light curves\n",
    "    ################################\n",
    "    \n",
    "    # create simulated light curve\n",
    "    drw_sim_t, drw_sim_y, drw_sim_yerr = eztao.ts.carma_sim.pred_lc(t, y, yerr, best_drw_arma, 1, t)\n",
    "    dho_sim_t, dho_sim_y, dho_sim_yerr = eztao.ts.carma_sim.pred_lc(t, y, yerr, theta_max_norm, 2, t)\n",
    "    \n",
    "    # directory to save plots to\n",
    "    plot_dir = 'carma_plots'\n",
    "    # plot drw\n",
    "    plot = True  \n",
    "    if plot:\n",
    "        matplotlib.pyplot.figure()\n",
    "        matplotlib.pyplot.errorbar(t, y, yerr=yerr, label='data',\n",
    "                                   linestyle=\"None\", marker='.', ms=3., color='purple', ecolor='0.8')\n",
    "        matplotlib.pyplot.plot(drw_sim_t, drw_sim_y, label=f'drw {best_drw_arma}')\n",
    "        matplotlib.pyplot.legend()\n",
    "        matplotlib.pyplot.savefig(f'{plot_dir}/{file_name}_drw_fit.png')\n",
    "        matplotlib.pyplot.close()\n",
    "\n",
    "        # plot dho\n",
    "        matplotlib.pyplot.figure()\n",
    "        matplotlib.pyplot.errorbar(t, y, yerr=yerr, label='data',\n",
    "                                   linestyle=\"None\", marker='.', ms=3., color='purple', ecolor='0.8')\n",
    "        matplotlib.pyplot.plot(dho_sim_t, dho_sim_y, label=f'dho {theta_max_norm}')\n",
    "        matplotlib.pyplot.legend()\n",
    "        matplotlib.pyplot.savefig(f'{plot_dir}/{file_name}_dho_fit.png')\n",
    "        matplotlib.pyplot.close()\n",
    "    \n",
    "    ################################\n",
    "    # Determine best fit\n",
    "    ################################\n",
    "    \n",
    "    # get chi-squared from sim light curves\n",
    "    chisq_drw = chisqg(y, drw_sim_y, yerr)\n",
    "    chisq_dho = chisqg(y, dho_sim_y, yerr)\n",
    "    \n",
    "    # determine best fit\n",
    "    best_fit = 'DRW'\n",
    "    if chisq_drw > chisq_dho and not numpy.isinf(chisq_dho):\n",
    "        best_fit = 'DHO'\n",
    "    \n",
    "    ################################\n",
    "    # Return\n",
    "    ################################\n",
    "    \n",
    "    return file_name, ra, dec, key[2], t, y_real, yerr_real, best_drw, best_drw_arma, chisq_drw, best_dho, theta_max_norm, theta_max_probability, chisq_dho, best_fit, lc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38774013-c967-4521-bcf4-280b1f72c990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pp with 24 workers\n",
      "C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " <string>:52: RuntimeWarning: overflow encountered in exp\n",
      " <string>:52: RuntimeWarning: overflow encountered in exp\n",
      " <string>:52: RuntimeWarning: overflow encountered in exp\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " <string>:52: RuntimeWarning: overflow encountered in exp\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " <string>:52: RuntimeWarning: overflow encountered in exp\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000<string>:36: RuntimeWarning: divide by zero encountered in true_divide\n",
      "An error has occured during the function execution\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\ppft\\__main__.py\", line 111, in run\n",
      "    __result = __f(*__args)\n",
      "  File \"<string>\", line 49, in getCARMAstats\n",
      "  File \"C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\eztao\\ts\\carma_fit.py\", line 415, in drw_fit\n",
      "    min_dt = np.min(t[1:] - t[:-1])\n",
      "  File \"<__array_function__ internals>\", line 5, in amin\n",
      "  File \"C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 2858, in amin\n",
      "    return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n",
      "  File \"C:\\Users\\Caleb\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 87, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      " "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14096/1316351447.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# start job\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_drw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_drw_arma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchisq_drw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_dho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_mcmc_dho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdho_probability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchisq_dho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlc_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# save data from job\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "ppservers = ()\n",
    "\n",
    "# creates jobserver with ncpus workers\n",
    "ncpus = 24\n",
    "job_server = pp.Server(ncpus, ppservers=ppservers)\n",
    "\n",
    "print(\"Starting pp with\", job_server.get_ncpus(), \"workers\")\n",
    "\n",
    "# read-in FP df\n",
    "file = 'BAT_AGN_ZTF_ForcedPhotometry_LightCurves_AllBands.parquet'\n",
    "df = pandas.read_parquet(file)\n",
    "\n",
    "# create list of keys based on a given filter\n",
    "filter_type = 'g'\n",
    "keys = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['filter'] == filter_type:\n",
    "        keys.append([file, filter_type, row['field']])\n",
    "\n",
    "# raise runtime exception if no keys are generated\n",
    "if len(keys) == 0:\n",
    "    raise ValueError(f'No keys were found: keys = {keys}')\n",
    "    \n",
    "# intialize lists to save to\n",
    "file_names = []\n",
    "ras = []\n",
    "decs =[]\n",
    "fields = []\n",
    "times = []\n",
    "magnitudes = []\n",
    "mag_errors = []\n",
    "best_fit_drws = []\n",
    "best_fit_drws_arma = []\n",
    "best_fit_dhos = []\n",
    "best_mcmc_dhos = []\n",
    "dho_probabilities = []\n",
    "chi_squared_drw = []\n",
    "chi_squared_dho = []\n",
    "best_fits = []\n",
    "lc_lengths = []\n",
    "\n",
    "# Submit a list of jobs running getCARMAstats for each file in repository\n",
    "# getCARMAstats - the function\n",
    "# (key,) - [filter_type, field] function parameter\n",
    "# (chisqg, ...) - tuple with functions on which getCARMAstats depends\n",
    "# (\"numpy\", ...) - tuple with package dependencies to be imported\n",
    "jobs = [(key, job_server.submit(getCARMAstats ,(key,), \n",
    "                                 (get_carma_parameter, lnprior_perturb, lnprior_bounds, lnlike, lnprob, chisqg,), \n",
    "                                 (\"numpy\", \"matplotlib.pyplot\", \"pandas\", \"emcee\", \"eztao\", \"eztao.ts\",\n",
    "                                  \"celerite\"))) for key in keys]\n",
    "\n",
    "job_num = 1\n",
    "for file, job in jobs:\n",
    "    # start job\n",
    "    file_name, ra, dec, field, t, y, yerr, best_drw, best_drw_arma, chisq_drw, best_dho, best_mcmc_dho, dho_probability, chisq_dho, best_fit, lc_length = job()\n",
    "        \n",
    "    # save data from job\n",
    "    file_names.append(file_name)\n",
    "    ras.append(ra)\n",
    "    decs.append(dec)\n",
    "    fields.append(field)\n",
    "    times.append(t)\n",
    "    magnitudes.append(y)\n",
    "    mag_errors.append(yerr)\n",
    "    best_fit_drws.append(best_drw)\n",
    "    best_fit_drws_arma.append(best_drw_arma)\n",
    "    chi_squared_drw.append(chisq_drw)\n",
    "    best_fit_dhos.append(best_dho)\n",
    "    best_mcmc_dhos.append(best_mcmc_dho)\n",
    "    dho_probabilities.append(dho_probability)\n",
    "    chi_squared_dho.append(chisq_dho)\n",
    "    best_fits.append(best_fit)\n",
    "    lc_lengths.append(lc_length)\n",
    "    \n",
    "    #print(f'Completed [{job_num}/{len(jobs)}]: {file_name}')\n",
    "    job_num += 1\n",
    "\n",
    "job_server.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62bbc4a-8291-4c4e-b5b8-dbc8df7470ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "agn_fit_data = pandas.DataFrame({'Filenames': file_names, 'RA': ras, 'DEC': decs, 'field': fields, 'Times (JD)': times, \n",
    "                                 'Magnitudes': magnitudes, 'Mag Errors': mag_errors, \n",
    "                                 'Best DRW Fit': best_fit_drws, 'Best DRW ARMA Fit': best_fit_drws_arma, 'DRW chisq': chi_squared_drw,\n",
    "                                 'Best DHO Fit': best_fit_dhos, 'DHO MCMC Fit': best_mcmc_dhos, 'DHO MCMC Probability': dho_probabilities, 'DHO chisq': chi_squared_dho,\n",
    "                                 'Best Fit': best_fits, 'LC Length': lc_lengths})\n",
    "\n",
    "# save dataframe\n",
    "agn_fit_data.to_parquet('ANG_FP_g_FitData.parquet')\n",
    "agn_fit_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
