{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09af76a7-ffc5-4755-9b67-8f356d4c3e3b",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3aa92e5-e71f-4578-82cf-ea95bd5cb663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import pandas\n",
    "import glob\n",
    "import emcee\n",
    "\n",
    "import eztao\n",
    "import eztao.ts\n",
    "\n",
    "import celerite\n",
    "\n",
    "import pp\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b2305-50d3-4cf6-8c02-140c0d834832",
   "metadata": {},
   "source": [
    "#### Define functions used in CARMA process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf2c2ab-220c-4128-bda2-c7086edcb2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi-sqared\n",
    "def chisqg(y_data, y_model, sd=None):\n",
    "    chisq = numpy.nansum(((y_data-y_model)/sd)**2)\n",
    "    return chisq\n",
    "\n",
    "################################\n",
    "# Define the prior and log-probability functions for MCMC\n",
    "################################\n",
    "\n",
    "# prior function for tau_perturb\n",
    "def lnprior_perturb(theta):\n",
    "    \"\"\"Prior on perturbation timescale. Note: this is a wedge like prior.\"\"\"\n",
    "\n",
    "    # determine DHO timescales\n",
    "    log10_tau_perturb = (theta[-1] - theta[-2])/numpy.log(10)\n",
    "    if -3 <= log10_tau_perturb <= 5:\n",
    "        prior = 0\n",
    "    else:\n",
    "        prior = -(numpy.abs(log10_tau_perturb - 1) - 4)\n",
    "\n",
    "    return prior\n",
    "\n",
    "def lnprior_bounds(theta):\n",
    "    \"\"\"Prior on AR and MA parameters. This is a flat prior.\"\"\"\n",
    "\n",
    "    # Place some bounds on the parameter space\n",
    "    bounds_low = numpy.array([-15, -15, -20, -20])\n",
    "    bounds_high = numpy.array([15, 15, 10, 10])\n",
    "\n",
    "    log_a1, log_a2, log_b0, log_b1 = theta\n",
    "    if ( \n",
    "        bounds_low[0] < log_a1 < bounds_high[0] \n",
    "        and bounds_low[1] < log_a2 < bounds_high[1] \n",
    "        and bounds_low[2] < log_b0 < bounds_high[2] \n",
    "        and bounds_low[3] < log_b1 < bounds_high[3] \n",
    "       ):\n",
    "        return 0.0\n",
    "    return -numpy.inf\n",
    "\n",
    "# We'll use the eztao version which effectively returns \"gp.log_likelihood\" from the GP and np.inf otherwise\n",
    "def lnlike(theta, y, gp):\n",
    "    return -eztao.ts.neg_param_ll(theta, y, gp)\n",
    "\n",
    "def lnprob(theta, y, gp):\n",
    "    lp_bounds = lnprior_bounds(theta)\n",
    "    lp_perturb = lnprior_perturb(theta)                              \n",
    "    if not numpy.isfinite(lp_bounds):\n",
    "        return -numpy.inf\n",
    "    return lp_bounds + lp_perturb + lnlike(theta, y, gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f97800-a611-4c2f-b95a-28beaec7478f",
   "metadata": {},
   "source": [
    "CARMA Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5743546e-bcd0-47ee-8968-1a982b93b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCARMAstats(file):\n",
    "    ################################\n",
    "    # setup\n",
    "    ################################\n",
    "\n",
    "    file_name = file[5:-4]\n",
    "    #file_name = file[5:-8]\n",
    "    \n",
    "    # read-in light curve\n",
    "    df = pandas.read_csv(file)\n",
    "\n",
    "    # obtain values from df\n",
    "    ra = df['ra'].values[0]\n",
    "    dec = df['dec'].values[0]\n",
    "    t = df['mjd'].values\n",
    "    y_real = df['mag'].values\n",
    "    yerr_real = df['magerr'].values\n",
    "    lc_length = len(t)\n",
    "    \n",
    "    # invert the magnitudes\n",
    "    y_real_inverted = (min(y_real)-y_real)\n",
    "\n",
    "    # normalize to unit standard deviation and zero mean\n",
    "    y = (y_real_inverted - numpy.mean(y_real_inverted))/numpy.std(y_real_inverted)\n",
    "    yerr = yerr_real/numpy.std(y_real_inverted)\n",
    "        \n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # DRW Process\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    # obtain best-fit\n",
    "    best_drw = eztao.ts.drw_fit(t, y, yerr)\n",
    "    \n",
    "    # define celerite GP model\n",
    "    #drw_gp = celerite.GP(eztao.carma.DRW_term(*numpy.log(best_drw)), mean=numpy.median(y_real))\n",
    "    #drw_gp.compute(t, yerr_real)\n",
    "    \n",
    "    # define log prob function\n",
    "    #def param_ll(*args):\n",
    "    #    return -eztao.ts.neg_param_ll(*args)\n",
    "\n",
    "    # initialize the walker, specify number of walkers, prob function, args and etc.\n",
    "    #initial = numpy.array(numpy.log(best_drw))\n",
    "    #ndim, nwalkers = len(initial), 32\n",
    "    #sampler_drw = emcee.EnsembleSampler(nwalkers, ndim, param_ll, args=[y_real, drw_gp])\n",
    "\n",
    "    # run a burn-in surrounding the best-fit parameters obtained above\n",
    "    #p0 = initial + 1e-8 * numpy.random.randn(nwalkers, ndim)\n",
    "    #p0, lp, _ = sampler_drw.run_mcmc(p0, 500)\n",
    "\n",
    "    # clear up the stored chain from burn-in, rerun the MCMC\n",
    "    #sampler_drw.reset()\n",
    "    #sampler_drw.run_mcmc(p0, 2000);\n",
    "    \n",
    "    # remove points with low prob for the sake of making good corner plot\n",
    "    #prob_threshold_drw = numpy.percentile(sampler_drw.flatlnprobability, 3)\n",
    "    #clean_chain_drw = sampler_drw.flatchain[sampler_drw.flatlnprobability > prob_threshold_drw, :]\n",
    "        \n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # DHO Process\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    # obtain best-fit\n",
    "    bounds = [(-15, 15), (-15, 15), (-20, 10), (-20, 10)]\n",
    "    best_dho = eztao.ts.dho_fit(t, y, yerr, user_bounds=bounds)\n",
    "\n",
    "    # Create the GP model -- instead of creating a \"model\" function that is then called by the \"lnlike\" function from tutorial,\n",
    "    #  we will create a GP that will be passed as an argument to the MCMC sampler. This will be the \"gp\" that is passed to\n",
    "    #  the \"lnprob\" and \"param_ll\" functions\n",
    "    dho_kernel = eztao.carma.DHO_term(*numpy.log(best_dho))\n",
    "    dho_gp = celerite.GP(dho_kernel, mean=numpy.median(y))\n",
    "    dho_gp.compute(t, yerr)\n",
    "\n",
    "    ################################\n",
    "    # MCMC\n",
    "    ################################\n",
    "\n",
    "    # Initalize MCMC\n",
    "    data = (t, y, yerr)\n",
    "    nwalkers = 128\n",
    "    niter = 2048\n",
    "\n",
    "    initial = numpy.array(numpy.log(best_dho))\n",
    "    ndim = len(initial)\n",
    "    p0 = [numpy.array(initial) + 1e-7 * numpy.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "    # Create the MCMC sampler -- note that the GP is passed as an argument in addition to the data\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=[y, dho_gp])\n",
    "\n",
    "    # run a burn-in surrounding the best-fit parameters obtained above\n",
    "    p0, lp, _ = sampler.run_mcmc(p0, 200)\n",
    "    sampler.reset()\n",
    "\n",
    "    # clear up the stored chain from burn-in, rerun the MCMC\n",
    "    pos, prob, state = sampler.run_mcmc(p0, niter);\n",
    "\n",
    "    ################################\n",
    "    # Obtain the Best Fit: theta_max\n",
    "    ################################\n",
    "\n",
    "    # put all the samples that explored in MCMC into a single array\n",
    "    samples = sampler.flatchain\n",
    "    \n",
    "    # find the parameters that have the best fit \n",
    "    theta_max_index = numpy.argmax(sampler.flatlnprobability)\n",
    "    theta_max_probability = sampler.flatlnprobability[theta_max_index]\n",
    "   \n",
    "    theta_max  = samples[theta_max_index] # these are in log-space\n",
    "    theta_max_norm = numpy.exp(theta_max) # take the exponent to get into 'normal' space\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # Simulate and Return\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    ################################\n",
    "    # Simulate and plot light curves\n",
    "    ################################\n",
    "    \n",
    "    # create simulated light curve\n",
    "    drw_sim_t, drw_sim_y, drw_sim_yerr = eztao.ts.carma_sim.pred_lc(t, y, yerr, best_drw, 1, t)\n",
    "    dho_sim_t, dho_sim_y, dho_sim_yerr = eztao.ts.carma_sim.pred_lc(t, y, yerr, theta_max_norm, 2, t)\n",
    "    \n",
    "    # directory to save plots to\n",
    "    plot_dir = 'carma_plots'\n",
    "    \n",
    "    # plot drw\n",
    "    matplotlib.pyplot.figure()\n",
    "    matplotlib.pyplot.errorbar(t, y, yerr=yerr, label='data',\n",
    "                               linestyle=\"None\", marker='.', ms=3., color='purple', ecolor='0.8')\n",
    "    matplotlib.pyplot.plot(drw_sim_t, drw_sim_y, label='drw best fit')\n",
    "    matplotlib.pyplot.legend()\n",
    "    matplotlib.pyplot.savefig(f'{plot_dir}/{file_name}_drw_fit.png')\n",
    "    \n",
    "    # plot dho\n",
    "    matplotlib.pyplot.figure()\n",
    "    matplotlib.pyplot.errorbar(t, y, yerr=yerr, label='data',\n",
    "                               linestyle=\"None\", marker='.', ms=3., color='purple', ecolor='0.8')\n",
    "    matplotlib.pyplot.plot(dho_sim_t, dho_sim_y, label='dho best fit')\n",
    "    matplotlib.pyplot.legend()\n",
    "    matplotlib.pyplot.savefig(f'{plot_dir}/{file_name}_dho_fit.png')\n",
    "    \n",
    "    ################################\n",
    "    # Determine best fit\n",
    "    ################################\n",
    "    \n",
    "    # get chi-squared from sim light curves\n",
    "    chisq_drw = chisqg(y, drw_sim_y, yerr)\n",
    "    chisq_dho = chisqg(y, dho_sim_y, yerr)\n",
    "    \n",
    "    # determine best fit\n",
    "    best_fit = 'DRW'\n",
    "    if chisq_drw > chisq_dho and not numpy.isinf(chisq_dho):\n",
    "        best_fit = 'DHO'\n",
    "    \n",
    "    ################################\n",
    "    # Return\n",
    "    ################################\n",
    "    \n",
    "    return file_name, ra, dec, t, y_real, yerr_real, best_drw, chisq_drw, best_dho, theta_max_norm, theta_max_probability, chisq_dho, best_fit, lc_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4df97b-6b94-4c07-a60a-499ed20c17e6",
   "metadata": {},
   "source": [
    "#### Parallel Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6bae9ca-751d-40ec-b3dd-2fdccf3c7acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pp with 2 workers\n",
      "C:\\Users\\caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " C:\\Users\\caleb\\anaconda3\\lib\\site-packages\\celerite\\celerite.py:467: RuntimeWarning: underflow encountered in multiply\n",
      "  var = -np.sum(KxsT * self.apply_inverse(KxsT), axis=0)\n",
      " Time elapsed:  127.34472513198853\n",
      "               Filenames          RA        DEC  \\\n",
      "0           3C273_ZTF_lc  187.277928   2.052405   \n",
      "1  KIC9650712_agn_ztf_lc  292.459966  46.373041   \n",
      "\n",
      "                                         Times (MJD)  \\\n",
      "0  [58199.3034259, 58214.2387037, 58214.2424306, ...   \n",
      "1  [58197.4333218, 58216.3896065, 58216.5171759, ...   \n",
      "\n",
      "                                          Magnitudes  \\\n",
      "0  [13.1205835, 13.1172094, 13.1140127, 13.124488...   \n",
      "1  [16.522049, 16.542526, 16.517281, 16.51273, 16...   \n",
      "\n",
      "                                          Mag Errors  \\\n",
      "0  [0.0123677235, 0.0123718372, 0.0123757366, 0.0...   \n",
      "1  [0.0134103056, 0.0134811746, 0.0133939954, 0.0...   \n",
      "\n",
      "                                 Best DRW Fit   DRW_chi_sq  \\\n",
      "0  [0.9908539527232003, 0.007846196175393555]  7669.161688   \n",
      "1     [1.5610057688640464, 892.9739956695595]     0.000001   \n",
      "\n",
      "                                        Best DHO Fit  \\\n",
      "0  [1883.0992115750537, 4.130652611409352, 106.32...   \n",
      "1  [0.1385204788922579, 0.00034821410476866744, 0...   \n",
      "\n",
      "                                        DHO MCMC Fit  DHO MCMC Probability  \\\n",
      "0  [1855.678560828071, 4.013649106320509, 105.354...           -206.099068   \n",
      "1  [0.14486741302365327, 0.000354778426217745, 0....            723.077805   \n",
      "\n",
      "   DHO_chi_sq Best Fit  LC Length  \n",
      "0    8.848804      DHO        280  \n",
      "1  806.725532      DRW       1081  \n"
     ]
    }
   ],
   "source": [
    "# get list of data files\n",
    "repository = glob.glob('data/*.csv')\n",
    "#repository = glob.glob('data/*.parquet')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "ppservers = ()\n",
    "\n",
    "# creates jobserver with ncpus workers\n",
    "ncpus = 2\n",
    "job_server = pp.Server(ncpus, ppservers=ppservers)\n",
    "\n",
    "print(\"Starting pp with\", job_server.get_ncpus(), \"workers\")\n",
    "\n",
    "# intialize lists to save to\n",
    "file_names = []\n",
    "times = []\n",
    "magnitudes = []\n",
    "mag_errors = []\n",
    "ras = []\n",
    "decs =[]\n",
    "best_fit_drws = []\n",
    "best_fit_dhos = []\n",
    "best_mcmc_dhos = []\n",
    "dho_probabilities = []\n",
    "chi_squared_drw = []\n",
    "chi_squared_dho = []\n",
    "best_fits = []\n",
    "lc_lengths = []\n",
    "\n",
    "# Submit a list of jobs running getCARMAstats for each file in repository\n",
    "# getCARMAstats - the function\n",
    "# (file,) - file with AGN lc\n",
    "# (chisqg, ...) - tuple with functions on which getCARMAstats depends\n",
    "# (\"numpy\", ...) - tuple with package dependencies to be imported\n",
    "jobs = [(file, job_server.submit(getCARMAstats ,(file,), \n",
    "                                 (chisqg, lnprior_perturb, lnprior_bounds, lnlike, lnprob,), \n",
    "                                 (\"numpy\", \"matplotlib.pyplot\", \"pandas\", \"emcee\", \"eztao\", \"eztao.ts\",\n",
    "                                  \"celerite\"))) for file in repository]\n",
    "\n",
    "#job_num = 1\n",
    "for file, job in jobs:\n",
    "    # start job\n",
    "    file_name, ra, dec, t, y, yerr, best_drw, chisq_drw, best_dho, best_mcmc_dho, dho_probability, chisq_dho, best_fit, lc_length = job()\n",
    "        \n",
    "    # save data from job\n",
    "    file_names.append(file_name)\n",
    "    ras.append(ra)\n",
    "    decs.append(dec)\n",
    "    times.append(t)\n",
    "    magnitudes.append(y)\n",
    "    mag_errors.append(yerr)\n",
    "    best_fit_drws.append(best_drw)\n",
    "    chi_squared_drw.append(chisq_drw)\n",
    "    best_fit_dhos.append(best_dho)\n",
    "    best_mcmc_dhos.append(best_mcmc_dho)\n",
    "    dho_probabilities.append(dho_probability)\n",
    "    chi_squared_dho.append(chisq_dho)\n",
    "    best_fits.append(best_fit)\n",
    "    lc_lengths.append(lc_length)\n",
    "    \n",
    "    #print(f'Completed [{job_num}/{len(jobs)}]: {file_name}')\n",
    "    #job_num += 1\n",
    "    \n",
    "agn_fit_data = pandas.DataFrame({'Filenames': file_names, 'RA': ras, 'DEC': decs, 'Times (MJD)': times, \n",
    "                                 'Magnitudes': magnitudes, 'Mag Errors': mag_errors, \n",
    "                                 'Best DRW Fit': best_fit_drws, 'DRW_chi_sq': chi_squared_drw,\n",
    "                                 'Best DHO Fit': best_fit_dhos, 'DHO MCMC Fit': best_mcmc_dhos, 'DHO MCMC Probability': dho_probabilities, 'DHO_chi_sq': chi_squared_dho,\n",
    "                                 'Best Fit': best_fits, 'LC Length': lc_lengths})\n",
    "\n",
    "print(\"Time elapsed: \", time.time() - start_time)\n",
    "\n",
    "print(agn_fit_data)\n",
    "\n",
    "#job_server.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d364f-61f7-48a4-b273-ce59d214c968",
   "metadata": {},
   "source": [
    "#### Create the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7a116ab-5625-4be5-ad7a-5c21c442ec96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-eae767410c05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m agn_fit_data = pandas.DataFrame({'Filenames': file_names, 'RA': ras, 'DEC': decs, 'Times (MJD)': times, \n\u001b[0m\u001b[0;32m      2\u001b[0m                                  \u001b[1;34m'Magnitudes'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmagnitudes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Mag Errors'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmag_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                  \u001b[1;34m'Best DRW Fit'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbest_fit_drws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DRW_chi_sq'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mchi_squared_drw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                  \u001b[1;34m'Best DHO Fit'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbest_fit_dhos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DHO MCMC Fit'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbest_mcmc_dhos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DHO MCMC Probability'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdho_probabilities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DHO_chi_sq'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mchi_squared_dho\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                  'Best Fit': best_fits, 'LC Length': lc_lengths})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ras' is not defined"
     ]
    }
   ],
   "source": [
    "agn_fit_data = pandas.DataFrame({'Filenames': file_names, 'RA': ras, 'DEC': decs, 'Times (MJD)': times, \n",
    "                                 'Magnitudes': magnitudes, 'Mag Errors': mag_errors, \n",
    "                                 'Best DRW Fit': best_fit_drws, 'DRW_chi_sq': chi_squared_drw,\n",
    "                                 'Best DHO Fit': best_fit_dhos, 'DHO MCMC Fit': best_mcmc_dhos, 'DHO MCMC Probability': dho_probabilities, 'DHO_chi_sq': chi_squared_dho,\n",
    "                                 'Best Fit': best_fits, 'LC Length': lc_lengths})\n",
    "\n",
    "agn_fit_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
