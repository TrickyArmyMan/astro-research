{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e36d9055-bd86-40a8-a0fd-3da9e4b47fd1",
   "metadata": {},
   "source": [
    "### Parallel Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f26f416-0af1-479e-a5c6-7efe1743784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import pandas\n",
    "import glob\n",
    "import emcee\n",
    "\n",
    "import eztao\n",
    "import eztao.ts\n",
    "\n",
    "import celerite\n",
    "\n",
    "import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b45e37-239b-4113-871a-48ade212d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Define CARMA function for DRW\n",
    "################################\n",
    "\n",
    "def get_carma_parameter(log_tau, log_amp):\n",
    "    \"\"\"Get DRW parameters in CARMA notation (alpha_*/beta_*).\n",
    "\n",
    "    alpha_1 = -1 / tau\n",
    "    sigma^2 = tau * sigma_kbs^2 / 2\n",
    "    sigma_kbs = np.sqrt( 2 * sigma^2 / tau )\n",
    "    beta_0 = sigma_kbs\n",
    "\n",
    "    Returns:\n",
    "        [alpha_1, beta_0].\n",
    "    \"\"\"\n",
    "    return [-1.0 / numpy.exp(log_tau), numpy.sqrt( 2.0 * numpy.exp(log_amp)**2.0 / numpy.exp(log_tau))]\n",
    "\n",
    "################################\n",
    "# Define the prior and log-probability functions for MCMC\n",
    "################################\n",
    "\n",
    "# prior function for tau_perturb\n",
    "def lnprior_perturb(theta):\n",
    "    \"\"\"Prior on perturbation timescale. Note: this is a wedge like prior.\"\"\"\n",
    "\n",
    "    # determine DHO timescales\n",
    "    log10_tau_perturb = (theta[-1] - theta[-2])/numpy.log(10)\n",
    "    if -3 <= log10_tau_perturb <= 5:\n",
    "        prior = 0\n",
    "    else:\n",
    "        prior = -(numpy.abs(log10_tau_perturb - 1) - 4)\n",
    "\n",
    "    return prior\n",
    "\n",
    "def lnprior_bounds(theta):\n",
    "    \"\"\"Prior on AR and MA parameters. This is a flat prior.\"\"\"\n",
    "\n",
    "    # Place some bounds on the parameter space\n",
    "    bounds_low = numpy.array([-15, -15, -20, -20])\n",
    "    bounds_high = numpy.array([15, 15, 10, 10])\n",
    "\n",
    "    log_a1, log_a2, log_b0, log_b1 = theta\n",
    "    if ( \n",
    "        bounds_low[0] < log_a1 < bounds_high[0] \n",
    "        and bounds_low[1] < log_a2 < bounds_high[1] \n",
    "        and bounds_low[2] < log_b0 < bounds_high[2] \n",
    "        and bounds_low[3] < log_b1 < bounds_high[3] \n",
    "       ):\n",
    "        return 0.0\n",
    "    return -numpy.inf\n",
    "\n",
    "# We'll use the eztao version which effectively returns \"gp.log_likelihood\" from the GP and np.inf otherwise\n",
    "def lnlike(theta, y, gp):\n",
    "    return -eztao.ts.neg_param_ll(theta, y, gp)\n",
    "\n",
    "def lnprob(theta, y, gp):\n",
    "    lp_bounds = lnprior_bounds(theta)\n",
    "    lp_perturb = lnprior_perturb(theta)                              \n",
    "    if not numpy.isfinite(lp_bounds):\n",
    "        return -numpy.inf\n",
    "    return lp_bounds + lp_perturb + lnlike(theta, y, gp)\n",
    "\n",
    "################################\n",
    "# Define other functions\n",
    "################################\n",
    "\n",
    "# chi-sqared\n",
    "def chisqg(y_data, y_model, sd=None):\n",
    "    chisq = numpy.nansum(((y_data-y_model)/sd)**2)\n",
    "    return chisq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022f2c88-16b5-42f7-a8bf-78e0b5860e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getCARMAstats(file):\n",
    "    ################################\n",
    "    # setup\n",
    "    ################################\n",
    "\n",
    "    #file_name = file[5:-4]\n",
    "    #file_name = file[5:-8]\n",
    "    file_name = file[22:-8]\n",
    "    \n",
    "    # read-in light curve\n",
    "    df = pandas.read_csv(file)\n",
    "\n",
    "    # obtain values from df\n",
    "    ra = df['ra'].values[0]\n",
    "    dec = df['dec'].values[0]\n",
    "    t = df['mjd'].values\n",
    "    y_real = df['mag'].values\n",
    "    yerr_real = df['magerr'].values\n",
    "    lc_length = len(t)\n",
    "    \n",
    "    # invert the magnitudes\n",
    "    y_real_inverted = (min(y_real)-y_real)\n",
    "\n",
    "    # normalize to unit standard deviation and zero mean\n",
    "    y = (y_real_inverted - numpy.mean(y_real_inverted))/numpy.std(y_real_inverted)\n",
    "    yerr = yerr_real/numpy.std(y_real_inverted)\n",
    "        \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # DRW Process\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    # obtain best-fit\n",
    "    bounds = [(0.01, 10.0), (0.01, 10.0)]\n",
    "    best_drw = eztao.ts.drw_fit(t, y, yerr, user_bounds=bounds)\n",
    "    \n",
    "    def get_carma_parameter(log_tau, log_amp):\n",
    "    \"\"\"Get DRW parameters in CARMA notation (alpha_*/beta_*).\n",
    "\n",
    "    alpha_1 = -1 / tau\n",
    "    sigma^2 = tau * sigma_kbs^2 / 2\n",
    "    sigma_kbs = np.sqrt( 2 * sigma^2 / tau )\n",
    "    beta_0 = sigma_kbs\n",
    "\n",
    "    Returns:\n",
    "        [alpha_1, beta_0].\n",
    "    \"\"\"\n",
    "    return [-1.0 / numpy.exp(log_tau), numpy.sqrt( 2.0 * numpy.exp(log_amp)**2.0 / numpy.exp(log_tau))]\n",
    "    \n",
    "    # get best-fit in CARMA space\n",
    "    best_drw_arma = numpy.exp(get_carma_parameter(best_drw[0], best_drw[1]))\n",
    "\n",
    "    # plot predicted time series\n",
    "    plot_pred_lc(t, y, err, best_drw_arma, 1, t)\n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # DHO Process\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    # obtain best-fit\n",
    "    bounds = [(-15, 15), (-15, 15), (-20, 10), (-20, 10)]\n",
    "    best_dho = eztao.ts.dho_fit(t, y, yerr, user_bounds=bounds)\n",
    "\n",
    "    # Create the GP model -- instead of creating a \"model\" function that is then called by the \"lnlike\" function from tutorial,\n",
    "    #  we will create a GP that will be passed as an argument to the MCMC sampler. This will be the \"gp\" that is passed to\n",
    "    #  the \"lnprob\" and \"param_ll\" functions\n",
    "    dho_kernel = eztao.carma.DHO_term(*numpy.log(best_dho))\n",
    "    dho_gp = celerite.GP(dho_kernel, mean=numpy.median(y))\n",
    "    dho_gp.compute(t, yerr)\n",
    "\n",
    "    ################################\n",
    "    # MCMC\n",
    "    ################################\n",
    "\n",
    "    # Initalize MCMC\n",
    "    data = (t, y, yerr)\n",
    "    nwalkers = 128\n",
    "    niter = 2048\n",
    "\n",
    "    initial = numpy.array(numpy.log(best_dho))\n",
    "    ndim = len(initial)\n",
    "    p0 = [numpy.array(initial) + 1e-7 * numpy.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "    # Create the MCMC sampler -- note that the GP is passed as an argument in addition to the data\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=[y, dho_gp])\n",
    "\n",
    "    # run a burn-in surrounding the best-fit parameters obtained above\n",
    "    p0, lp, _ = sampler.run_mcmc(p0, 200)\n",
    "    sampler.reset()\n",
    "\n",
    "    # clear up the stored chain from burn-in, rerun the MCMC\n",
    "    pos, prob, state = sampler.run_mcmc(p0, niter);\n",
    "\n",
    "    ################################\n",
    "    # Obtain the Best Fit: theta_max\n",
    "    ################################\n",
    "\n",
    "    # put all the samples that explored in MCMC into a single array\n",
    "    samples = sampler.flatchain\n",
    "    \n",
    "    # find the parameters that have the best fit \n",
    "    theta_max_index = numpy.argmax(sampler.flatlnprobability)\n",
    "    theta_max_probability = sampler.flatlnprobability[theta_max_index]\n",
    "   \n",
    "    theta_max  = samples[theta_max_index] # these are in log-space\n",
    "    theta_max_norm = numpy.exp(theta_max) # take the exponent to get into 'normal' space\n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ################################\n",
    "    #\n",
    "    # Simulate and Return\n",
    "    #\n",
    "    ################################\n",
    "    ################################\n",
    "    \n",
    "    ################################\n",
    "    # Simulate and plot light curves\n",
    "    ################################\n",
    "    \n",
    "    # create simulated light curve\n",
    "    drw_sim_t, drw_sim_y, drw_sim_yerr = eztao.ts.carma_sim.pred_lc(t, y, err, best_drw_arma, 1, t)\n",
    "    dho_sim_t, dho_sim_y, dho_sim_yerr = eztao.ts.carma_sim.pred_lc(t, y, yerr, theta_max_norm, 2, t)\n",
    "    \n",
    "    # directory to save plots to\n",
    "    plot_dir = 'plots-and-figures/carma_plots'\n",
    "    # plot drw\n",
    "    plot = True    \n",
    "    if plot:\n",
    "        matplotlib.pyplot.figure()\n",
    "        matplotlib.pyplot.errorbar(t, y, yerr=yerr, label='data',\n",
    "                                   linestyle=\"None\", marker='.', ms=3., color='purple', ecolor='0.8')\n",
    "        matplotlib.pyplot.plot(drw_sim_t, drw_sim_y, label=f'drw {best_drw}')\n",
    "        matplotlib.pyplot.legend()\n",
    "        matplotlib.pyplot.savefig(f'{plot_dir}/{file_name}_drw_fit.png')\n",
    "        matplotlib.pyplot.close()\n",
    "\n",
    "        # plot dho\n",
    "        matplotlib.pyplot.figure()\n",
    "        matplotlib.pyplot.errorbar(t, y, yerr=yerr, label='data',\n",
    "                                   linestyle=\"None\", marker='.', ms=3., color='purple', ecolor='0.8')\n",
    "        matplotlib.pyplot.plot(dho_sim_t, dho_sim_y, label=f'dho {theta_max_norm}')\n",
    "        matplotlib.pyplot.legend()\n",
    "        matplotlib.pyplot.savefig(f'{plot_dir}/{file_name}_dho_fit.png')\n",
    "        matplotlib.pyplot.close()\n",
    "    \n",
    "    ################################\n",
    "    # Determine best fit\n",
    "    ################################\n",
    "    \n",
    "    # get chi-squared from sim light curves\n",
    "    chisq_drw = chisqg(y, drw_sim_y, yerr)\n",
    "    chisq_dho = chisqg(y, dho_sim_y, yerr)\n",
    "    \n",
    "    # determine best fit\n",
    "    best_fit = 'DRW'\n",
    "    if chisq_drw > chisq_dho and not numpy.isinf(chisq_dho):\n",
    "        best_fit = 'DHO'\n",
    "    \n",
    "    ################################\n",
    "    # Return\n",
    "    ################################\n",
    "    \n",
    "    return file_name, ra, dec, t, y_real, yerr_real, best_drw, best_drw_arma, chisq_drw, best_dho, theta_max_norm, theta_max_probability, chisq_dho, best_fit, lc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efae6692-c5ae-4f3e-bbba-2c819ec6e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pp with 24 workers\n",
      "An error has occured during the function execution\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tricky\\anaconda3\\lib\\site-packages\\ppft\\__main__.py\", line 111, in run\n",
      "    __result = __f(*__args)\n",
      "  File \"<string>\", line 42, in getCARMAstats\n",
      "NameError: name 'get_carma_parameter' is not defined\n",
      " "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9400/4078810357.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# start job\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_drw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_drw_arma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchisq_drw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_dho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_mcmc_dho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdho_probability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchisq_dho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlc_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m# save data from job\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "ppservers = ()\n",
    "\n",
    "# creates jobserver with ncpus workers\n",
    "ncpus = 24\n",
    "job_server = pp.Server(ncpus, ppservers=ppservers)\n",
    "\n",
    "print(\"Starting pp with\", job_server.get_ncpus(), \"workers\")\n",
    "\n",
    "# get list of data files\n",
    "#repository = glob.glob('data/*.csv')\n",
    "repository = glob.glob('../../AGN_LightCurves/*.parquet')\n",
    "\n",
    "# intialize lists to save to\n",
    "file_names = []\n",
    "times = []\n",
    "magnitudes = []\n",
    "mag_errors = []\n",
    "ras = []\n",
    "decs =[]\n",
    "best_fit_drws = []\n",
    "best_fit_drws_arma = []\n",
    "best_fit_dhos = []\n",
    "best_mcmc_dhos = []\n",
    "dho_probabilities = []\n",
    "chi_squared_drw = []\n",
    "chi_squared_dho = []\n",
    "best_fits = []\n",
    "lc_lengths = []\n",
    "\n",
    "# Submit a list of jobs running getCARMAstats for each file in repository\n",
    "# getCARMAstats - the function\n",
    "# (file,) - file with AGN lc\n",
    "# (chisqg, ...) - tuple with functions on which getCARMAstats depends\n",
    "# (\"numpy\", ...) - tuple with package dependencies to be imported\n",
    "jobs = [(file, job_server.submit(getCARMAstats ,(file,), \n",
    "                                 (chisqg, lnprior_perturb, lnprior_bounds, lnlike, lnprob,), \n",
    "                                 (\"numpy\", \"matplotlib.pyplot\", \"pandas\", \"emcee\", \"eztao\", \"eztao.ts\",\n",
    "                                  \"celerite\"))) for file in repository]\n",
    "\n",
    "job_num = 1\n",
    "for file, job in jobs:\n",
    "    # start job\n",
    "    file_name, ra, dec, t, y, yerr, best_drw, best_drw_arma, chisq_drw, best_dho, best_mcmc_dho, dho_probability, chisq_dho, best_fit, lc_length = job()\n",
    "        \n",
    "    # save data from job\n",
    "    file_names.append(file_name)\n",
    "    ras.append(ra)\n",
    "    decs.append(dec)\n",
    "    times.append(t)\n",
    "    magnitudes.append(y)\n",
    "    mag_errors.append(yerr)\n",
    "    best_fit_drws.append(best_drw)\n",
    "    best_fit_drws_arma.append(best_drw_arma)\n",
    "    chi_squared_drw.append(chisq_drw)\n",
    "    best_fit_dhos.append(best_dho)\n",
    "    best_mcmc_dhos.append(best_mcmc_dho)\n",
    "    dho_probabilities.append(dho_probability)\n",
    "    chi_squared_dho.append(chisq_dho)\n",
    "    best_fits.append(best_fit)\n",
    "    lc_lengths.append(lc_length)\n",
    "    \n",
    "    # print(f'Completed [{job_num}/{len(jobs)}]: {file_name}')\n",
    "    job_num += 1\n",
    "\n",
    "job_server.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc302832-1502-43ed-b962-e01cb756d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "agn_fit_data = pandas.DataFrame({'Filenames': file_names, 'RA': ras, 'DEC': decs, 'Times (MJD)': times, \n",
    "                                 'Magnitudes': magnitudes, 'Mag Errors': mag_errors, \n",
    "                                 'Best DRW Fit': best_fit_drws, 'Best DRW ARMA Fit': best_fit_drws_arma, 'DRW_chi_sq': chi_squared_drw,\n",
    "                                 'Best DHO Fit': best_fit_dhos, 'DHO MCMC Fit': best_mcmc_dhos, 'DHO MCMC Probability': dho_probabilities, 'DHO_chi_sq': chi_squared_dho,\n",
    "                                 'Best Fit': best_fits, 'LC Length': lc_lengths})\n",
    "\n",
    "# save dataframe\n",
    "agn_fit_data.to_csv('updated_agn_fit_data.csv')\n",
    " \n",
    "agn_fit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1672fb36-dbab-4b94-bf2f-943fd4484c87",
   "metadata": {},
   "source": [
    "### Timescales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e0773c-d8de-4062-a8fd-50b813eeeda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dho_timescales(params):\n",
    "\n",
    "    \"\"\"Compute a couple DHO timescales from CARMA parameters.\n",
    "\n",
    "    - damping factor\n",
    "    - decay timescale\n",
    "    - rise/damped QPO timescale\n",
    "    - perturbation timescale\n",
    "    - decorrelation timescale\n",
    "    - natural oscillation frequency\n",
    "    \"\"\"\n",
    "   \n",
    "    # expand params\n",
    "    a1, a2, b0, b1 = params  \n",
    "\n",
    "    # damping factor & natural frequency\n",
    "    xi = a1/(2*np.sqrt(a2))\n",
    "    omega_0 = np.sqrt(a2)   \n",
    "\n",
    "    # placeholder for two timescales\n",
    "    tau_perturb = b1/b0\n",
    "    tau_decay = 0\n",
    "    tau_rise_dqpo = 0\n",
    "    tau_decorr = 0\n",
    "\n",
    "    roots = np.roots([1, a1, a2])\n",
    "    if xi < 1:\n",
    "        tau_decay = np.abs(1/roots[0].real)\n",
    "        tau_rise_dqpo = 2*np.pi*np.abs(1/roots[0].imag)/np.sqrt(1 - xi**2)\n",
    "        tau_decorr = (np.pi/2)*np.pi*2/omega_0\n",
    "    else:\n",
    "        tau_decay = np.abs(1/np.max(roots.real))\n",
    "        tau_rise_dqpo = np.abs(1/np.min(roots.real))\n",
    "        tau_decorr = (tau_decay + tau_rise_dqpo)*np.pi/2\n",
    " \n",
    "    return np.array([xi, tau_decay, tau_rise_dqpo, tau_perturb, tau_decorr, omega_0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
